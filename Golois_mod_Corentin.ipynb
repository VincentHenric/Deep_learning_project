{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Proj_Corentin.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentHenric/Deep_learning_project/blob/master/Golois_mod_Corentin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y6ZketP9tIF",
        "colab_type": "code",
        "outputId": "924abd9f-6851-400d-e4bc-bef66ca25e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "  \n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IENEPga99Up",
        "colab_type": "code",
        "outputId": "dfb068d2-f506-41ee-d287-11bb541aba09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "try:\n",
        "  import tensorflow.compat.v2 as tf\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAoLToVM-QCi",
        "colab_type": "code",
        "outputId": "131d7a55-9931-4859-90f7-42f076021127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#if pybind11 is not installed\n",
        "#pip install pybind11"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pybind11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/4d/ae1c4d8e8b139afa9682054dd42df3b0e3b5c1731287933021b9fd7e9cc4/pybind11-2.4.3-py2.py3-none-any.whl (150kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 26.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 71kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 81kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 92kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 8.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rYa8ehz-Smi",
        "colab_type": "code",
        "outputId": "7d727ce6-ac05-46a6-f6ce-81c978e06fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#Connect to our own Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7QTRc5AAFwx",
        "colab_type": "code",
        "outputId": "a9f6748a-208e-435e-8282-b494c103671d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#Go on the DL project folder\n",
        "%cd \"/content/gdrive/My Drive/DeepLearningProject/\"\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/DeepLearningProject\n",
            "Board.h        games.data\t\t\t       policy.npy\n",
            "compileMAC.sh  games.txt\t\t\t       __pycache__\n",
            "compile.sh     golois.cpp\t\t\t       README\n",
            "convert        golois.cpython-37m-x86_64-linux-gnu.so  Rzone.h\n",
            "convert.cpp    golois.py\t\t\t       save.py\n",
            "DL_Proj.ipynb  input_data.npy\t\t\t       value.npy\n",
            "end.npy        ls.sh\n",
            "Game.h\t       models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z2IjAfpAOgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run golois.py\n",
        "#!python golois.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSoSLnfED3_x",
        "colab_type": "code",
        "outputId": "6e24c353-845f-4a9f-b4b0-3756efeeb5e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers \n",
        "from datetime import datetime\n",
        "import os\n",
        "#import golois\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input, Dropout, MaxPooling2D, Conv2D, BatchNormalization, Activation\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "planes = 8\n",
        "moves = 361\n",
        "dynamicBatch = False\n",
        "if dynamicBatch:\n",
        "    N = 100000\n",
        "    input_data = np.random.randint(2, size=(N, 19, 19, planes))\n",
        "    input_data = input_data.astype ('float32')\n",
        "    \n",
        "    policy = np.random.randint(moves, size=(N,))\n",
        "    policy = keras.utils.to_categorical (policy)\n",
        "    \n",
        "    value = np.random.randint(2, size=(N,))\n",
        "    value = value.astype ('float32')\n",
        "    \n",
        "    end = np.random.randint(2, size=(N, 19, 19, 2))\n",
        "    end = end.astype ('float32')\n",
        "\n",
        "    golois.getBatch (input_data, policy, value, end)\n",
        "else:\n",
        "    input_data = np.load ('input_data.npy')\n",
        "    policy = np.load ('policy.npy')\n",
        "    value = np.load ('value.npy')\n",
        "    end = np.load ('end.npy')\n",
        "\n",
        "input = keras.Input(shape=(19, 19, planes), name='board')\n",
        "\n",
        "x = layers.Conv2D(42, 3, padding='same')(input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "ident = x\n",
        "x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = layers.add([ident,x])\n",
        "ident2 = x\n",
        "x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = layers.add([ident2,x])\n",
        "\n",
        "policy_head = layers.Conv2D(2, 1, padding='same')(x)\n",
        "policy_head = BatchNormalization()(policy_head)\n",
        "policy_head = Activation('relu')(policy_head)\n",
        "policy_head = layers.Flatten()(policy_head)\n",
        "policy_head = layers.Dense(moves, activation='softmax', name='policy')(policy_head)\n",
        "\n",
        "value_head = layers.Conv2D(1, 1, padding='same')(x)\n",
        "value_head = BatchNormalization()(value_head)\n",
        "value_head = Activation('relu')(value_head)\n",
        "value_head = layers.Flatten()(value_head)\n",
        "value_head = layers.Dense(256, activation='relu')(value_head)\n",
        "value_head = layers.Dense(1, activation='tanh', name='value')(value_head)\n",
        "\n",
        "model = keras.Model(inputs=input, outputs=[policy_head, value_head])\n",
        "model.summary()\n",
        "\n",
        "#Name of the model, to save it later\n",
        "now = datetime.now()\n",
        "date_time = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
        "save_dir = os.path.join(os.getcwd(), 'models')\n",
        "model_name = 'dl_proj_model_' + date_time + '.h5'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_30\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "board (InputLayer)              [(None, 19, 19, 8)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 19, 19, 42)   3066        board[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 19, 19, 42)   168         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 19, 19, 42)   0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 19, 19, 128)  48512       activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 19, 19, 128)  512         conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 19, 19, 128)  0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 19, 19, 128)  147584      activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 19, 19, 128)  512         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 19, 19, 128)  0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 19, 19, 128)  147584      activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 19, 19, 128)  512         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 19, 19, 128)  0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 19, 19, 128)  0           activation_246[0][0]             \n",
            "                                                                 activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 19, 19, 128)  147584      add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 19, 19, 128)  512         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 19, 19, 128)  0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 19, 19, 128)  147584      activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 19, 19, 128)  512         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 19, 19, 128)  0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 19, 19, 128)  0           add_64[0][0]                     \n",
            "                                                                 activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 19, 19, 1)    129         add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 19, 19, 2)    258         add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 19, 19, 1)    4           conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 19, 19, 2)    8           conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 19, 19, 1)    0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 19, 19, 2)    0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_61 (Flatten)            (None, 361)          0           activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_60 (Flatten)            (None, 722)          0           activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 256)          92672       flatten_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "policy (Dense)                  (None, 361)          261003      flatten_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "value (Dense)                   (None, 1)            257         dense_25[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 998,973\n",
            "Trainable params: 997,603\n",
            "Non-trainable params: 1,370\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMsAG8h-FsDQ",
        "colab_type": "code",
        "outputId": "1cdf7e91-8719-458a-fb6e-4eebedf994f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "#Save only the best model\n",
        "#Problem : multiple output // j'ai pas encore vu comment checker les deux outputs\n",
        "model_save = ModelCheckpoint(model_path, monitor='val_policy_loss', verbose=1, save_best_only=True, mode='min')\n",
        "#Avoid wasting time\n",
        "earlyStopping = EarlyStopping(monitor=\"val_policy_loss\",patience=15)\n",
        "callbacks_list = [model_save, earlyStopping]\n",
        "\n",
        "model.compile(optimizer='Adam',\n",
        "              loss={'value': 'mse', 'policy': 'categorical_crossentropy'})\n",
        "\n",
        "model.fit(input_data, {'policy': policy, 'value': value},\n",
        "           epochs=40, batch_size=128, validation_split=0.2, callbacks=callbacks_list)\n",
        "\n",
        "print(\"Saved model : \" + model_path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80000 samples, validate on 20000 samples\n",
            "Epoch 1/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 5.4353 - policy_loss: 5.1803 - value_loss: 0.2550\n",
            "Epoch 00001: val_policy_loss improved from inf to 4.65521, saving model to /content/gdrive/My Drive/DeepLearningProject/models/dl_proj_model_12-04-2019_22-28-48.h5\n",
            "80000/80000 [==============================] - 20s 254us/sample - loss: 5.4333 - policy_loss: 5.1783 - value_loss: 0.2550 - val_loss: 4.8975 - val_policy_loss: 4.6552 - val_value_loss: 0.2410\n",
            "Epoch 2/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 4.5950 - policy_loss: 4.3536 - value_loss: 0.2414\n",
            "Epoch 00002: val_policy_loss improved from 4.65521 to 4.25313, saving model to /content/gdrive/My Drive/DeepLearningProject/models/dl_proj_model_12-04-2019_22-28-48.h5\n",
            "80000/80000 [==============================] - 19s 243us/sample - loss: 4.5943 - policy_loss: 4.3529 - value_loss: 0.2414 - val_loss: 4.5008 - val_policy_loss: 4.2531 - val_value_loss: 0.2461\n",
            "Epoch 3/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 3.9811 - policy_loss: 3.7403 - value_loss: 0.2409\n",
            "Epoch 00003: val_policy_loss improved from 4.25313 to 3.78823, saving model to /content/gdrive/My Drive/DeepLearningProject/models/dl_proj_model_12-04-2019_22-28-48.h5\n",
            "80000/80000 [==============================] - 20s 244us/sample - loss: 3.9809 - policy_loss: 3.7400 - value_loss: 0.2409 - val_loss: 4.0323 - val_policy_loss: 3.7882 - val_value_loss: 0.2424\n",
            "Epoch 4/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 3.4540 - policy_loss: 3.2136 - value_loss: 0.2404\n",
            "Epoch 00004: val_policy_loss did not improve from 3.78823\n",
            "80000/80000 [==============================] - 19s 235us/sample - loss: 3.4532 - policy_loss: 3.2128 - value_loss: 0.2404 - val_loss: 4.0600 - val_policy_loss: 3.8184 - val_value_loss: 0.2408\n",
            "Epoch 5/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 3.0426 - policy_loss: 2.8033 - value_loss: 0.2393\n",
            "Epoch 00005: val_policy_loss improved from 3.78823 to 3.71389, saving model to /content/gdrive/My Drive/DeepLearningProject/models/dl_proj_model_12-04-2019_22-28-48.h5\n",
            "80000/80000 [==============================] - 20s 244us/sample - loss: 3.0437 - policy_loss: 2.8044 - value_loss: 0.2393 - val_loss: 3.9565 - val_policy_loss: 3.7139 - val_value_loss: 0.2415\n",
            "Epoch 6/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 2.7107 - policy_loss: 2.4719 - value_loss: 0.2388\n",
            "Epoch 00006: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 237us/sample - loss: 2.7109 - policy_loss: 2.4721 - value_loss: 0.2388 - val_loss: 4.3783 - val_policy_loss: 4.1364 - val_value_loss: 0.2421\n",
            "Epoch 7/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 2.4441 - policy_loss: 2.2058 - value_loss: 0.2383\n",
            "Epoch 00007: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 236us/sample - loss: 2.4439 - policy_loss: 2.2056 - value_loss: 0.2383 - val_loss: 4.1833 - val_policy_loss: 3.9420 - val_value_loss: 0.2413\n",
            "Epoch 8/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 2.2078 - policy_loss: 1.9707 - value_loss: 0.2371\n",
            "Epoch 00008: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 235us/sample - loss: 2.2086 - policy_loss: 1.9715 - value_loss: 0.2371 - val_loss: 4.6075 - val_policy_loss: 4.3630 - val_value_loss: 0.2430\n",
            "Epoch 9/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 1.9893 - policy_loss: 1.7536 - value_loss: 0.2357\n",
            "Epoch 00009: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 235us/sample - loss: 1.9903 - policy_loss: 1.7546 - value_loss: 0.2357 - val_loss: 4.7556 - val_policy_loss: 4.5121 - val_value_loss: 0.2427\n",
            "Epoch 10/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 1.7928 - policy_loss: 1.5597 - value_loss: 0.2331\n",
            "Epoch 00010: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 235us/sample - loss: 1.7939 - policy_loss: 1.5608 - value_loss: 0.2332 - val_loss: 4.9512 - val_policy_loss: 4.7069 - val_value_loss: 0.2440\n",
            "Epoch 11/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 1.6105 - policy_loss: 1.3828 - value_loss: 0.2277\n",
            "Epoch 00011: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 236us/sample - loss: 1.6126 - policy_loss: 1.3849 - value_loss: 0.2276 - val_loss: 5.3675 - val_policy_loss: 5.1162 - val_value_loss: 0.2512\n",
            "Epoch 12/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 1.4213 - policy_loss: 1.2031 - value_loss: 0.2181\n",
            "Epoch 00012: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 236us/sample - loss: 1.4220 - policy_loss: 1.2039 - value_loss: 0.2182 - val_loss: 5.7321 - val_policy_loss: 5.4780 - val_value_loss: 0.2537\n",
            "Epoch 13/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 1.2374 - policy_loss: 1.0330 - value_loss: 0.2044\n",
            "Epoch 00013: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 237us/sample - loss: 1.2383 - policy_loss: 1.0339 - value_loss: 0.2044 - val_loss: 6.4913 - val_policy_loss: 6.2243 - val_value_loss: 0.2677\n",
            "Epoch 14/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 1.0770 - policy_loss: 0.8880 - value_loss: 0.1890\n",
            "Epoch 00014: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 236us/sample - loss: 1.0780 - policy_loss: 0.8890 - value_loss: 0.1891 - val_loss: 6.9262 - val_policy_loss: 6.6536 - val_value_loss: 0.2728\n",
            "Epoch 15/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 0.9315 - policy_loss: 0.7570 - value_loss: 0.1744\n",
            "Epoch 00015: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 236us/sample - loss: 0.9325 - policy_loss: 0.7581 - value_loss: 0.1744 - val_loss: 7.5405 - val_policy_loss: 7.2595 - val_value_loss: 0.2834\n",
            "Epoch 16/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 0.7983 - policy_loss: 0.6390 - value_loss: 0.1594\n",
            "Epoch 00016: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 232us/sample - loss: 0.7994 - policy_loss: 0.6400 - value_loss: 0.1594 - val_loss: 7.9518 - val_policy_loss: 7.6552 - val_value_loss: 0.2946\n",
            "Epoch 17/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 0.7191 - policy_loss: 0.5710 - value_loss: 0.1482\n",
            "Epoch 00017: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 234us/sample - loss: 0.7198 - policy_loss: 0.5716 - value_loss: 0.1482 - val_loss: 8.6662 - val_policy_loss: 8.3701 - val_value_loss: 0.2955\n",
            "Epoch 18/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 0.6322 - policy_loss: 0.4952 - value_loss: 0.1370\n",
            "Epoch 00018: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 235us/sample - loss: 0.6327 - policy_loss: 0.4956 - value_loss: 0.1371 - val_loss: 8.4673 - val_policy_loss: 8.1652 - val_value_loss: 0.3007\n",
            "Epoch 19/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 0.5706 - policy_loss: 0.4415 - value_loss: 0.1291\n",
            "Epoch 00019: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 236us/sample - loss: 0.5713 - policy_loss: 0.4422 - value_loss: 0.1291 - val_loss: 9.4077 - val_policy_loss: 9.0988 - val_value_loss: 0.3118\n",
            "Epoch 20/40\n",
            "79744/80000 [============================>.] - ETA: 0s - loss: 0.5272 - policy_loss: 0.4069 - value_loss: 0.1204\n",
            "Epoch 00020: val_policy_loss did not improve from 3.71389\n",
            "80000/80000 [==============================] - 19s 237us/sample - loss: 0.5281 - policy_loss: 0.4077 - value_loss: 0.1204 - val_loss: 9.2457 - val_policy_loss: 8.9261 - val_value_loss: 0.3205\n",
            "Saved model : /content/gdrive/My Drive/DeepLearningProject/models/dl_proj_model_12-04-2019_22-28-48.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-20WyprZGN7v",
        "colab_type": "code",
        "outputId": "a291bb35-7c84-495e-ee2f-fe7e76e45b02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "#Run and evaluate  the last\n",
        "import glob\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#Take the latest_file, i.e. the latest model\n",
        "save_dir = os.path.join(os.getcwd(), 'models')\n",
        "save_dir = save_dir+'/*'\n",
        "list_of_files = glob.glob(save_dir) \n",
        "latest_file = max(list_of_files, key=os.path.getctime)\n",
        "model_name = latest_file\n",
        "\n",
        "model_path = model_name\n",
        "model = load_model(model_path)\n",
        "\n",
        "score = model.evaluate(x_test,y_test,batch_size=64,verbose = 0)\n",
        "print ('Validation accuracy', model.metrics_names, score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-2029057b4ef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Validation accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
          ]
        }
      ]
    }
  ]
}