{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to tf 2.0 (run on colab)\n",
    "# !pip uninstall tensorflow\n",
    "# !pip install tensorflow==2.0.0\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load git code\n",
    "# !git clone -s https://VincentHenric:@github.com/VincentHenric/Deep_learning_project.git\n",
    "# %cd Deep_learning_project\n",
    "# !ls\n",
    "\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use dynamic batches\n",
    "# !pip install pybind11\n",
    "# !./compile.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access Drive\n",
    "from google.colab import drive\n",
    "%cd /content/\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Move data to working folder\n",
    "# %cp -a \"../gdrive/My Drive/deep_learning_project/.\" \".\"\n",
    "# %ls\n",
    "\n",
    "# Go to Drive folder\n",
    "%cd gdrive/My Drive/deep_learning_project\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import golois\n",
    "\n",
    "%aimport models\n",
    "%aimport utils\n",
    "%aimport generators\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLANES = 8\n",
    "MOVES = 361\n",
    "DYNAMIC_BATCH = True\n",
    "model_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DYNAMIC_BATCH:\n",
    "#     N = 100000\n",
    "#     input_data = np.random.randint(2, size=(N, 19, 19, PLANES))\n",
    "#     input_data = input_data.astype ('float32')\n",
    "    \n",
    "#     policy = np.random.randint(MOVES, size=(N,))\n",
    "#     policy = keras.utils.to_categorical (policy)\n",
    "    \n",
    "#     value = np.random.randint(2, size=(N,))\n",
    "#     value = value.astype ('float32')\n",
    "    \n",
    "#     end = np.random.randint(2, size=(N, 19, 19, 2))\n",
    "#     end = end.astype ('float32')\n",
    "\n",
    "#     golois.getBatch (input_data, policy, value, end)\n",
    "    \n",
    "    generator = generators.GoloisSequence(N=100000,\n",
    "                                          batch_size=128,\n",
    "                                          change_batch=5,\n",
    "                                          planes=PLANES,\n",
    "                                          moves=MOVES)\n",
    "    input_data_val = np.load ('input_data.npy')\n",
    "    policy_val = np.load ('policy.npy')\n",
    "    value_val = np.load ('value.npy')\n",
    "    end_val = np.load ('end.npy')\n",
    "    \n",
    "else:\n",
    "    input_data = np.load ('input_data.npy')\n",
    "    policy = np.load ('policy.npy')\n",
    "    value = np.load ('value.npy')\n",
    "    end = np.load ('end.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_files = os.listdir('models')\n",
    "models_files = [file[:-3] for file in models_files if file.endswith('.h5')]\n",
    "if model_name in models_files:\n",
    "    print(\"The model already exists: loading model\")\n",
    "    model = keras.models.load_model('models/{}.h5'.format(model_name))\n",
    "else:\n",
    "    print(\"New model\")\n",
    "    model = models.get_model_week2(128)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'value': 'mse', 'policy': 'categorical_crossentropy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='models/{}.h5'.format(model_name),\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True)\n",
    "\n",
    "print('Start learning')\n",
    "# history = model.fit(input_data, {'policy': policy, 'value': value},\n",
    "#           epochs=20, batch_size=128, validation_split=0.1,\n",
    "#           callbacks=[checkpointer])\n",
    "\n",
    "history = model.fit_generator(generator,\n",
    "          epochs=20, validation_data=(input_data_val, (policy_val, value_val)),\n",
    "          callbacks=[checkpointer], shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, figsize=(10,10))\n",
    "\n",
    "ax[0].plot(history.history['loss'], label=\"loss\")\n",
    "ax[0].plot(history.history['val_loss'], label = \"val loss\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(history.history['policy_loss'], label=\"policy loss\")\n",
    "ax[1].plot(history.history['val_policy_loss'], label = \"val policy loss\")\n",
    "ax[1].legend()\n",
    "ax[2].plot(history.history['value_loss'], label=\"value loss\")\n",
    "ax[2].plot(history.history['val_value_loss'], label = \"val value loss\")\n",
    "ax[2].legend()\n",
    "\n",
    "plt.xlabel('nb epochs')\n",
    "# plt.title(key)\n",
    "# plt.savefig('history.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_history(history.history, model_name, 'a', path='histories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model\n",
    "files.download('models/{}.h5'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the history\n",
    "files.download('histories/{}.json'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/HENRIC.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
